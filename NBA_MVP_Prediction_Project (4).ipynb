{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# National Basketball Association's Most Valuable Player Prediction\n",
    "\n",
    "In this project I performed data wrangling to obtain the data for the last 20 years for MVP prediction. After importing data from basketballreference.com, I cleaned it using pandas and made it ready for analysis. In the analysis part, I used Random Forest Regressor to predict the percentage of vote shares and hence predicted the ranks. I got an average precision of 93% for predicting the top 5 MVP candidates for the year 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 : WEB SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For years 2003 - 2022\n",
    "years = list(range(2003, 2023))\n",
    "url_start = \"https://www.basketball-reference.com/awards/awards_{}.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years : \n",
    "    url = url_start.format(year)\n",
    "    data = requests.get(url)\n",
    "    \n",
    "    with open(\"mvps/{}.html\".format(year), \"w+\", encoding = \"utf-8\") as f:\n",
    "        f.write(data.text)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mvps/2008.html\", encoding = \"utf-8\") as f:\n",
    "    page = f.read()\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "soup.find('tr', class_ = \"over_header\").decompose()\n",
    "mvp_table = soup.find(id = 'mvp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in years:\n",
    "    with open(\"mvps/{}.html\".format(year), encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    soup.find('tr', class_ = \"over_header\").decompose()\n",
    "    mvp_table = soup.find(id = 'mvp')\n",
    "    mvp = pd.read_html(str(mvp_table))[0]\n",
    "    mvp[\"Year\"] = year\n",
    "    \n",
    "    dfs.append(mvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_data = pd.concat(dfs)\n",
    "mvp_data.to_csv(\"mvps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Players Datasets\n",
    "players = []\n",
    "for year in range(2003, 2023):\n",
    "    path = \"C:\\\\Users\\\\dhruv\\\\OneDrive\\\\Desktop\\\\nba_data\\\\{}.xlsx\".format(year)\n",
    "    df = pd.read_excel(path)\n",
    "    df[\"Year\"] = year\n",
    "    players.append(df)\n",
    "\n",
    "player_data = pd.concat(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Player-additional</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tariq Abdul-Wahad</td>\n",
       "      <td>SG</td>\n",
       "      <td>28.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>abdulta01</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Shareef Abdur-Rahim</td>\n",
       "      <td>PF</td>\n",
       "      <td>26.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>...</td>\n",
       "      <td>6.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>abdursh01</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Courtney Alexander</td>\n",
       "      <td>PG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NOH</td>\n",
       "      <td>66.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>alexaco02</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Malik Allen</td>\n",
       "      <td>PF</td>\n",
       "      <td>24.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>allenma01</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ray Allen*</td>\n",
       "      <td>SG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>TOT</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>37.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>17.9</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>22.5</td>\n",
       "      <td>allenra02</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rk               Player Pos   Age   Tm     G    GS    MP   FG   FGA  ...  \\\n",
       "0  1    Tariq Abdul-Wahad  SG  28.0  DAL  14.0   0.0  14.6  1.9   4.1  ...   \n",
       "1  2  Shareef Abdur-Rahim  PF  26.0  ATL  81.0  81.0  38.1  7.0  14.6  ...   \n",
       "2  3   Courtney Alexander  PG  25.0  NOH  66.0   7.0  20.6  2.9   7.7  ...   \n",
       "3  4          Malik Allen  PF  24.0  MIA  80.0  73.0  29.0  4.2   9.9  ...   \n",
       "4  5           Ray Allen*  SG  27.0  TOT  76.0  75.0  37.9  7.9  17.9  ...   \n",
       "\n",
       "   DRB  TRB  AST  STL  BLK  TOV   PF   PTS  Player-additional  Year  \n",
       "0  1.9  2.9  1.5  0.4  0.2  0.5  1.9   4.1          abdulta01  2003  \n",
       "1  6.2  8.4  3.0  1.1  0.5  2.6  3.0  19.9          abdursh01  2003  \n",
       "2  1.2  1.8  1.2  0.5  0.1  1.0  1.9   7.9          alexaco02  2003  \n",
       "3  3.6  5.3  0.7  0.5  1.0  1.6  2.9   9.6          allenma01  2003  \n",
       "4  3.8  5.0  4.4  1.4  0.2  2.6  2.9  22.5          allenra02  2003  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_standings.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years :\n",
    "    url = team_stats_url.format(year)\n",
    "\n",
    "    data = requests.get(url)\n",
    "    with open(\"team/{}.html\".format(year), \"w+\", encoding = \"utf-8\") as f :\n",
    "        f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'decompose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     page \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      6\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m, class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdecompose()\n\u001b[0;32m      8\u001b[0m team_table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivs_standings_E\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m team \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(\u001b[38;5;28mstr\u001b[39m(team_table))[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'decompose'"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for year in years :\n",
    "    with open(\"team/{}.html\".format(year), encoding = \"utf-8\") as f :\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    soup.find('tr', class_ = \"thead\").decompose()\n",
    "    team_table = soup.find(id = 'divs_standings_E')\n",
    "    team = pd.read_html(str(team_table))[0]\n",
    "    team[\"Year\"] = year\n",
    "    team[\"Team\"] = team[\"Eastern Conference\"]\n",
    "    del team[\"Eastern Conference\"]\n",
    "    dfs.append(team)\n",
    "\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    soup.find('tr', class_ = \"thead\").decompose()\n",
    "    team_table = soup.find(id = 'divs_standings_W')\n",
    "    team = pd.read_html(str(team_table))[0]\n",
    "    team[\"Year\"] = year\n",
    "    team[\"Team\"] = team[\"Western Conference\"]\n",
    "    del team[\"Western Conference\"]\n",
    "    dfs.append(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.concat(dfs)\n",
    "teams.to_csv(\"teams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 : DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps = pd.read_csv(\"mvps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking necessary columns from \"mvps\" dataset.\n",
    "mvps = mvps[[\"Player\", \"Year\", \"Pts Won\", \"Pts Max\",\"Share\"]]\n",
    "mvps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = player_data\n",
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del players[\"Rk\"]\n",
    "del players[\"Player-additional\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players[\"Player\"].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players[\"Player\"] = players[\"Player\"].str.replace(\"*\", \"\", regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players[\"Player\"].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.groupby([\"Player\", \"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players who played for multiple teams in a single season\n",
    "def single_row(df) :\n",
    "    if df.shape[0] == 1 :\n",
    "        return df\n",
    "    else :\n",
    "        row = df[df[\"Tm\"] == \"TOT\"]\n",
    "        row[\"Tm\"] = df.iloc[-1, :][\"Tm\"]\n",
    "        return row\n",
    "    \n",
    "players = players.groupby([\"Player\", \"Year\"]).apply(single_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.index = players.index.droplevel()\n",
    "players.index = players.index.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining MVP and Players data\n",
    "merged = players.merge(mvps, how = \"outer\", on = [\"Player\", \"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[[\"Pts Won\",\"Pts Max\",\"Share\"]] = merged[[\"Pts Won\",\"Pts Max\",\"Share\"]].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.read_csv(\"teams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = teams[~teams[\"W\"].str.contains(\"Division\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del teams[\"Unnamed: 0\"]\n",
    "teams.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams[\"Team\"] = teams[\"Team\"].str.replace(\"*\", \"\", regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nickn = {}\n",
    "\n",
    "with open(\"C:\\\\Users\\\\dhruv\\\\Downloads\\\\nicknames.txt\") as f :\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:] :\n",
    "        abbr, name = line.replace(\"\\n\", \"\").split(\",\")\n",
    "        nickn[abbr] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nickn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"Team\"] = merged[\"Tm\"].map(nickn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = merged.merge(teams, how = \"outer\", on = [\"Team\", \"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stats.apply(pd.to_numeric, errors = \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"GB\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"GB\"] = stats[\"GB\"].str.replace(\"â€”\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"GB\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"GB\"] = pd.to_numeric(stats[\"GB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.to_csv(\"player_mvp_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 : Analysis and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stats = pd.read_csv(\"player_mvp_stats.csv\")\n",
    "del stats['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null values per column\n",
    "pd.isnull(stats).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stats.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['Age', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
    "       '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB',\n",
    "       'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Year',\n",
    "       'W', 'L', 'W/L%', 'GB', 'PS/G',\n",
    "       'PA/G', 'SRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and test Set\n",
    "train = stats[stats['Year'] < 2022]\n",
    "test = stats[stats['Year'] == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg_model = RandomForestRegressor(n_estimators = 11, random_state = 1, min_samples_split = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.fit(train[predictors], train['Share'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pred = reg_model.predict(test[predictors])\n",
    "reg_pred = pd.DataFrame(reg_pred, columns = ['reg_pred'], index = test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination = pd.concat([test[['Player', 'Share']], reg_pred], axis = 1 )\n",
    "combination.sort_values(\"Share\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(combination['Share'], combination['reg_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination = combination.sort_values(\"Share\", ascending = False)\n",
    "combination[\"Rk\"] = list(range(1, combination.shape[0] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination = combination.sort_values(\"reg_pred\", ascending = False)\n",
    "combination[\"Prediction Rk\"] = list(range(1, combination.shape[0] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination.sort_values(\"Share\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap(combination) :\n",
    "    actual = combination.sort_values(\"Share\", ascending = False).head()\n",
    "    pred = combination.sort_values(\"reg_pred\", ascending = False)\n",
    "    ps = []\n",
    "    found = 0\n",
    "    seen = 1\n",
    "    for index, row in pred.iterrows() : \n",
    "        if row[\"Player\"] in actual[\"Player\"].values :\n",
    "            found += 1\n",
    "            ps.append(found/seen)\n",
    "        seen += 1\n",
    "    return sum(ps)/len(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got average precision of 93% to predict the top 5 MVP candidates in 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "feature_importances = np.sort(reg_model.feature_importances_)\n",
    "feature_names = predictors  # Assuming your features are in a DataFrame\n",
    "sns.barplot(x=feature_importances, y=feature_names)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
